{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Progressiveness\" metric\n",
    "Based on document distance between treaties per year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be cleaned\n",
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.parsing.preprocessing import strip_short\n",
    "from pyemd import emd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open('../Visualisations/Stopwords_law.pkl','rb')  \n",
    "stopwords = pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing text\n",
    "def txt_cleaner(text):\n",
    "    meaningful_words = []\n",
    "    text = text.lower() #make all lowercase\n",
    "    #text = strip_short(text, minsize=4) #remove short words\n",
    "    tokens = word_tokenize(text) # returns list of words\n",
    "    tokens = [w for w in tokens if w.isalpha()] #remove punctuation, also numbers\n",
    "    stops = [stopwords][0]\n",
    "    tokens = [w for w in tokens if not w in stops] # remove stop words\n",
    "    for item in tokens: #filter short and long words\n",
    "        if len(item) >= 3 and len(item) < 30:\n",
    "            meaningful_words.append(item)\n",
    "    #count = Counter(meaningful_words) # Count most recurrent words\n",
    "    #most_occur = count.most_common(10) # Make list with n most recurrent\n",
    "    #most_occur = [item[0] for item in most_occur] # Get rid of the counter number\n",
    "    #meaningful_words = [w for w in meaningful_words if not w in most_occur] # remove most recurrent\n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search directory\n",
    "directory_in_str = \"../xml/\"\n",
    "directory = os.fsencode(directory_in_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing files to dataframe..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>year_signed</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pta_218.xml</td>\n",
       "      <td>218</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>1975</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>[denmark, ireland, great, britain, northern, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pta_230.xml</td>\n",
       "      <td>230</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>1972</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>[portuguese, desiring, consolidate, enlargemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pta_224.xml</td>\n",
       "      <td>224</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>1977</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[lebanon, overall, contributing, lebanon, help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pta_378.xml</td>\n",
       "      <td>378</td>\n",
       "      <td>Partial Scope Agreement</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>[mauritius, islamic, pakistan, islamic, pakist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pta_344.xml</td>\n",
       "      <td>344</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>[chile, chile, hereinafter, chile, desirous, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename   id                     type year_signed month day  \\\n",
       "0  pta_218.xml  218     Free Trade Agreement        1975     4  28   \n",
       "1  pta_230.xml  230     Free Trade Agreement        1972     7  22   \n",
       "2  pta_224.xml  224     Free Trade Agreement        1977     5   3   \n",
       "3  pta_378.xml  378  Partial Scope Agreement        2007     7  30   \n",
       "4  pta_344.xml  344     Free Trade Agreement        2009     7  14   \n",
       "\n",
       "                                                text  \n",
       "0  [denmark, ireland, great, britain, northern, i...  \n",
       "1  [portuguese, desiring, consolidate, enlargemen...  \n",
       "2  [lebanon, overall, contributing, lebanon, help...  \n",
       "3  [mauritius, islamic, pakistan, islamic, pakist...  \n",
       "4  [chile, chile, hereinafter, chile, desirous, f...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate base data frame\n",
    "print(\"Preprocessing files to dataframe..\")\n",
    "text_df = pd.DataFrame(columns=['filename', 'id','type', 'year_signed', 'month', 'day', 'text'])\n",
    "for n,file in enumerate(os.listdir(directory)):\n",
    "    new_row = []\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.XML') or filename.endswith('.xml'):\n",
    "        new_row.append(filename)\n",
    "        tree = ET.parse(directory_in_str + filename)\n",
    "        root = tree.getroot()\n",
    "        meta = root[0]\n",
    "        body = root[1]\n",
    "        if meta.find('language').text == 'en': \n",
    "            new_row.append(meta.find('treaty_identifier').text)\n",
    "            new_row.append(meta.find('type').text)\n",
    "            new_row.append(int(meta.find('date_signed').text.split('-')[0]))\n",
    "            new_row.append(int(meta.find('date_signed').text.split('-')[1]))\n",
    "            new_row.append(int(meta.find('date_signed').text.split('-')[2]))\n",
    "            text_raw = \"\"\n",
    "            for chapter in body.iter(): \n",
    "                text_raw += chapter.text\n",
    "            text_clean = txt_cleaner(text_raw)\n",
    "            new_row.append(text_clean)\n",
    "            text_df.loc[n] = new_row\n",
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>year_signed</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>pta_310.xml</td>\n",
       "      <td>Customs Union</td>\n",
       "      <td>1948</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>[informationof, south, africa, govern, ment, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>pta_254.xml</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>1951</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>[republics, nicaragua, salvador, nicaragua, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>pta_110.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>1957</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[consolidated, version, majesty, king, belgian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>pta_188.xml</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>1958</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>[text, xxviiiof, freetrade, intigration, afric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>pta_255.xml</td>\n",
       "      <td>Free Trade Agreement</td>\n",
       "      <td>1959</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>[congo, gabon, chad, merchandise, equatorial, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename                                            type year_signed  \\\n",
       "id                                                                             \n",
       "310  pta_310.xml                                   Customs Union        1948   \n",
       "254  pta_254.xml                            Free Trade Agreement        1951   \n",
       "110  pta_110.xml  Customs Union & Economic Integration Agreement        1957   \n",
       "188  pta_188.xml                            Free Trade Agreement        1958   \n",
       "255  pta_255.xml                            Free Trade Agreement        1959   \n",
       "\n",
       "    month day                                               text  \n",
       "id                                                                \n",
       "310    12   6  [informationof, south, africa, govern, ment, s...  \n",
       "254     3   9  [republics, nicaragua, salvador, nicaragua, sa...  \n",
       "110     3  25  [consolidated, version, majesty, king, belgian...  \n",
       "188     6  10  [text, xxviiiof, freetrade, intigration, afric...  \n",
       "255     6  23  [congo, gabon, chad, merchandise, equatorial, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'date_signed' column to datetime object\n",
    "#text_df['date_signed'] = pd.to_datetime(text_df.date_signed)\n",
    "\n",
    "# Sort items by date\n",
    "text_df.sort_values(by='year_signed', inplace=True)\n",
    "\n",
    "# Set 'id' as index (verify integrity in case of duplicates)\n",
    "text_df = text_df.set_index(['id'],verify_integrity=True)\n",
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save resulting dataframe to csv file\n",
    "#out_dir = \"saved_csv/glove-wiki-gigaword-300/\"\n",
    "\n",
    "#csv_out = \"text_df.csv\"\n",
    "#text_df.to_csv(out_dir + csv_out, index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "Here we define the selection of treaties we want to compare against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique years\n",
    "year_unique = text_df.year_signed.unique()\n",
    "# Get list of treaty types\n",
    "type_unique = text_df.type.unique()\n",
    "\n",
    "# Separate treaties by decade\n",
    "decades_slices =[[0,5],[5,13],[13,21],[21,28],[28,37],[37,47],[47,54]]\n",
    "\n",
    "# List of dataframes to iterate over\n",
    "decades_df = []\n",
    "types_df = []\n",
    "\n",
    "# Append 'decades' slices to list of dataframes\n",
    "for item in decades_slices:\n",
    "    decades_df.append(text_df[text_df.year_signed.isin(year_unique[item[0]:item[1]])])\n",
    "\n",
    "# Append treaties by type to list of dataframes\n",
    "for item in type_unique:\n",
    "    types_df.append(text_df[text_df.type.isin([item])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>year_signed</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>pta_110.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>1957</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[consolidated, version, majesty, king, belgian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>pta_128.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>1973</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[consolidate, bonds, historically, existed, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>pta_119.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>[mercosur, southern, mercosur, argentine, fede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>pta_85.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>[logo, east, east, august, whereas, uganda, ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>pta_441.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[treatyon, armenia, eurasian, dated, minsk, oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>pta_444.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>[nazira, translationtreatyon, kyrgyz, republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>pta_440.xml</td>\n",
       "      <td>Customs Union &amp; Economic Integration Agreement</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>[eurasian, belarus, kazakhstan, russian, feder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename                                            type year_signed  \\\n",
       "id                                                                             \n",
       "110  pta_110.xml  Customs Union & Economic Integration Agreement        1957   \n",
       "128  pta_128.xml  Customs Union & Economic Integration Agreement        1973   \n",
       "119  pta_119.xml  Customs Union & Economic Integration Agreement        1991   \n",
       "85    pta_85.xml  Customs Union & Economic Integration Agreement        1999   \n",
       "441  pta_441.xml  Customs Union & Economic Integration Agreement        2014   \n",
       "444  pta_444.xml  Customs Union & Economic Integration Agreement        2014   \n",
       "440  pta_440.xml  Customs Union & Economic Integration Agreement        2014   \n",
       "\n",
       "    month day                                               text  \n",
       "id                                                                \n",
       "110     3  25  [consolidated, version, majesty, king, belgian...  \n",
       "128     7   4  [consolidate, bonds, historically, existed, pe...  \n",
       "119     3  26  [mercosur, southern, mercosur, argentine, fede...  \n",
       "85     11  30  [logo, east, east, august, whereas, uganda, ke...  \n",
       "441    10  10  [treatyon, armenia, eurasian, dated, minsk, oc...  \n",
       "444    12  23  [nazira, translationtreatyon, kyrgyz, republic...  \n",
       "440     5  29  [eurasian, belarus, kazakhstan, russian, feder...  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df.type.isin([type_unique[2]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance calculations\n",
    "Compute distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained model\n",
    "model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure distance between treaties in same decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing from: 1948 to 1959\n",
      "Processing from: 1960 to 1969\n",
      "Processing from: 1970 to 1979\n",
      "Processing from: 1980 to 1988\n",
      "Processing from: 1991 to 1999\n",
      "Processing from: 2000 to 2009\n",
      "Processing from: 2010 to 2016\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>310</th>\n",
       "      <th>254</th>\n",
       "      <th>110</th>\n",
       "      <th>188</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524973</td>\n",
       "      <td>0.592487</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.914906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.524973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460972</td>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.643523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.592487</td>\n",
       "      <td>0.460972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467749</td>\n",
       "      <td>0.793777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.467749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.914906</td>\n",
       "      <td>0.643523</td>\n",
       "      <td>0.793777</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          310       254       110       188       255\n",
       "id                                                   \n",
       "310  0.000000  0.524973  0.592487  0.631757  0.914906\n",
       "254  0.524973  0.000000  0.460972  0.362904  0.643523\n",
       "110  0.592487  0.460972  0.000000  0.467749  0.793777\n",
       "188  0.631757  0.362904  0.467749  0.000000  0.785606\n",
       "255  0.914906  0.643523  0.793777  0.785606  0.000000"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decades_dist = [] #this is where we will store all our distance matrices\n",
    "for dfx in decades_df:\n",
    "    print(f'Processing from: {dfx.year_signed.min()} to {dfx.year_signed.max()}')\n",
    "    labels = list(dfx.index.values) #labels for dataframe\n",
    "    labels = ['id'] + labels #append 'id'\n",
    "    distances = []\n",
    "    for x in dfx.iterrows():\n",
    "        #print(f'Row: {x[0]}')\n",
    "        dist_tmp = [] #temporal list for current row\n",
    "        t1 = [words for sublist in x[1][5] for words in sublist]\n",
    "        dist_tmp.append(x[0]) #append index\n",
    "        for y in dfx.iterrows():\n",
    "            t2 = [words for sublist in y[1][5] for words in sublist]\n",
    "            d = model.wmdistance(t1, t2)\n",
    "            dist_tmp.append(d)\n",
    "        distances.append(dist_tmp) #once done with row, append to total distances\n",
    "    df = pd.DataFrame.from_records(distances, columns=labels, index=['id']) #once all distances for current df are coll\n",
    "    decades_dist.append(df)\n",
    "decades_dist[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save resulting dataframe to csv file\n",
    "#out_dir = \"saved_csv/glove-wiki-gigaword-300/decades_ollie_stopwords/\"\n",
    "\n",
    "#for n,item in enumerate(decades_dist):\n",
    "#    csv_out = \"decades_dist_\"+str(n)+\".csv\"\n",
    "#    item.to_csv(out_dir + csv_out, index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure distance between treaties of same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>310</th>\n",
       "      <th>219</th>\n",
       "      <th>164</th>\n",
       "      <th>172</th>\n",
       "      <th>226</th>\n",
       "      <th>210</th>\n",
       "      <th>243</th>\n",
       "      <th>267</th>\n",
       "      <th>116</th>\n",
       "      <th>100</th>\n",
       "      <th>322</th>\n",
       "      <th>203</th>\n",
       "      <th>111</th>\n",
       "      <th>32</th>\n",
       "      <th>109</th>\n",
       "      <th>429</th>\n",
       "      <th>97</th>\n",
       "      <th>15</th>\n",
       "      <th>6</th>\n",
       "      <th>426</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.129512</td>\n",
       "      <td>0.639307</td>\n",
       "      <td>0.864257</td>\n",
       "      <td>0.696658</td>\n",
       "      <td>0.794314</td>\n",
       "      <td>0.713057</td>\n",
       "      <td>0.555742</td>\n",
       "      <td>0.711764</td>\n",
       "      <td>1.084049</td>\n",
       "      <td>0.876650</td>\n",
       "      <td>0.748875</td>\n",
       "      <td>0.540154</td>\n",
       "      <td>0.587584</td>\n",
       "      <td>0.732770</td>\n",
       "      <td>0.634566</td>\n",
       "      <td>0.509592</td>\n",
       "      <td>0.860832</td>\n",
       "      <td>0.614681</td>\n",
       "      <td>0.909509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.129512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971891</td>\n",
       "      <td>1.319841</td>\n",
       "      <td>1.085745</td>\n",
       "      <td>0.758499</td>\n",
       "      <td>0.841790</td>\n",
       "      <td>0.900157</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.966445</td>\n",
       "      <td>1.261078</td>\n",
       "      <td>0.928909</td>\n",
       "      <td>0.920413</td>\n",
       "      <td>1.016011</td>\n",
       "      <td>0.910685</td>\n",
       "      <td>1.027017</td>\n",
       "      <td>0.998739</td>\n",
       "      <td>1.054567</td>\n",
       "      <td>0.946026</td>\n",
       "      <td>1.456037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.639307</td>\n",
       "      <td>0.971891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>0.454788</td>\n",
       "      <td>0.844805</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.648314</td>\n",
       "      <td>0.628061</td>\n",
       "      <td>0.918376</td>\n",
       "      <td>0.792682</td>\n",
       "      <td>0.802896</td>\n",
       "      <td>0.477872</td>\n",
       "      <td>0.659373</td>\n",
       "      <td>0.559694</td>\n",
       "      <td>0.610609</td>\n",
       "      <td>0.621837</td>\n",
       "      <td>0.699382</td>\n",
       "      <td>0.398657</td>\n",
       "      <td>0.826577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.864257</td>\n",
       "      <td>1.319841</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694160</td>\n",
       "      <td>0.985879</td>\n",
       "      <td>0.949693</td>\n",
       "      <td>0.735017</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.911147</td>\n",
       "      <td>0.910222</td>\n",
       "      <td>0.985872</td>\n",
       "      <td>0.594940</td>\n",
       "      <td>0.639184</td>\n",
       "      <td>0.683790</td>\n",
       "      <td>0.622057</td>\n",
       "      <td>0.649370</td>\n",
       "      <td>0.596922</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>0.726365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.696658</td>\n",
       "      <td>1.085745</td>\n",
       "      <td>0.454788</td>\n",
       "      <td>0.694160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976802</td>\n",
       "      <td>0.759234</td>\n",
       "      <td>0.802511</td>\n",
       "      <td>0.775029</td>\n",
       "      <td>1.022828</td>\n",
       "      <td>0.809914</td>\n",
       "      <td>0.875487</td>\n",
       "      <td>0.540154</td>\n",
       "      <td>0.726289</td>\n",
       "      <td>0.670844</td>\n",
       "      <td>0.639222</td>\n",
       "      <td>0.742448</td>\n",
       "      <td>0.800142</td>\n",
       "      <td>0.631551</td>\n",
       "      <td>0.648353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          310       219       164       172       226       210       243  \\\n",
       "id                                                                          \n",
       "310  0.000000  1.129512  0.639307  0.864257  0.696658  0.794314  0.713057   \n",
       "219  1.129512  0.000000  0.971891  1.319841  1.085745  0.758499  0.841790   \n",
       "164  0.639307  0.971891  0.000000  0.643035  0.454788  0.844805  0.769853   \n",
       "172  0.864257  1.319841  0.643035  0.000000  0.694160  0.985879  0.949693   \n",
       "226  0.696658  1.085745  0.454788  0.694160  0.000000  0.976802  0.759234   \n",
       "\n",
       "          267       116       100       322       203       111        32  \\\n",
       "id                                                                          \n",
       "310  0.555742  0.711764  1.084049  0.876650  0.748875  0.540154  0.587584   \n",
       "219  0.900157  0.917413  0.966445  1.261078  0.928909  0.920413  1.016011   \n",
       "164  0.648314  0.628061  0.918376  0.792682  0.802896  0.477872  0.659373   \n",
       "172  0.735017  0.736948  0.911147  0.910222  0.985872  0.594940  0.639184   \n",
       "226  0.802511  0.775029  1.022828  0.809914  0.875487  0.540154  0.726289   \n",
       "\n",
       "          109       429        97        15         6       426  \n",
       "id                                                               \n",
       "310  0.732770  0.634566  0.509592  0.860832  0.614681  0.909509  \n",
       "219  0.910685  1.027017  0.998739  1.054567  0.946026  1.456037  \n",
       "164  0.559694  0.610609  0.621837  0.699382  0.398657  0.826577  \n",
       "172  0.683790  0.622057  0.649370  0.596922  0.864461  0.726365  \n",
       "226  0.670844  0.639222  0.742448  0.800142  0.631551  0.648353  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_dist = [] #this is where we will store all our distance matrices\n",
    "for dfx in types_df:\n",
    "    #print(f'Processing: {dfx.type}')\n",
    "    labels = list(dfx.index.values) #labels for dataframe\n",
    "    labels = ['id'] + labels #append 'id'\n",
    "    distances = []\n",
    "    for x in dfx.iterrows():\n",
    "        #print(f'Row: {x[0]}')\n",
    "        dist_tmp = [] #temporal list for current row\n",
    "        t1 = [words for sublist in x[1][5] for words in sublist]\n",
    "        dist_tmp.append(x[0]) #append index\n",
    "        for y in dfx.iterrows():\n",
    "            t2 = [words for sublist in y[1][5] for words in sublist]\n",
    "            d = model.wmdistance(t1, t2)\n",
    "            dist_tmp.append(d)\n",
    "        distances.append(dist_tmp) #once done with row, append to total distances\n",
    "    df = pd.DataFrame.from_records(distances, columns=labels, index=['id']) #once all distances for current df are coll\n",
    "    types_dist.append(df)\n",
    "types_dist[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save resulting dataframe to csv file\n",
    "out_dir = \"saved_csv/glove-wiki-gigaword-300/types/\"\n",
    "\n",
    "for n,item in enumerate(types_dist):\n",
    "    csv_out = \"types_dist_\"+str(n)+\".csv\"\n",
    "    item.to_csv(out_dir + csv_out, index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure distance between all treaties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 310\n",
      "Row: 254\n",
      "Row: 110\n",
      "Row: 188\n",
      "Row: 255\n",
      "Row: 138\n",
      "Row: 275\n",
      "Row: 266\n",
      "Row: 175\n",
      "Row: 219\n",
      "Row: 164\n",
      "Row: 242\n",
      "Row: 316\n",
      "Row: 172\n",
      "Row: 274\n",
      "Row: 174\n",
      "Row: 187\n",
      "Row: 136\n",
      "Row: 173\n",
      "Row: 227\n",
      "Row: 240\n",
      "Row: 135\n",
      "Row: 317\n",
      "Row: 241\n",
      "Row: 222\n",
      "Row: 134\n",
      "Row: 237\n",
      "Row: 226\n",
      "Row: 133\n",
      "Row: 131\n",
      "Row: 130\n",
      "Row: 238\n",
      "Row: 207\n",
      "Row: 230\n",
      "Row: 213\n",
      "Row: 210\n",
      "Row: 128\n",
      "Row: 129\n",
      "Row: 217\n",
      "Row: 243\n",
      "Row: 127\n",
      "Row: 318\n",
      "Row: 218\n",
      "Row: 126\n",
      "Row: 206\n",
      "Row: 125\n",
      "Row: 224\n",
      "Row: 214\n",
      "Row: 239\n",
      "Row: 253\n",
      "Row: 319\n",
      "Row: 124\n",
      "Row: 267\n",
      "Row: 122\n",
      "Row: 320\n",
      "Row: 121\n",
      "Row: 116\n",
      "Row: 132\n",
      "Row: 186\n",
      "Row: 229\n",
      "Row: 211\n",
      "Row: 118\n",
      "Row: 220\n",
      "Row: 100\n",
      "Row: 216\n",
      "Row: 228\n",
      "Row: 119\n",
      "Row: 322\n",
      "Row: 120\n",
      "Row: 221\n",
      "Row: 420\n",
      "Row: 431\n",
      "Row: 280\n",
      "Row: 422\n",
      "Row: 108\n",
      "Row: 281\n",
      "Row: 423\n",
      "Row: 354\n",
      "Row: 43\n",
      "Row: 94\n",
      "Row: 251\n",
      "Row: 432\n",
      "Row: 105\n",
      "Row: 279\n",
      "Row: 259\n",
      "Row: 276\n",
      "Row: 262\n",
      "Row: 424\n",
      "Row: 114\n",
      "Row: 115\n",
      "Row: 263\n",
      "Row: 277\n",
      "Row: 278\n",
      "Row: 203\n",
      "Row: 260\n",
      "Row: 258\n",
      "Row: 264\n",
      "Row: 112\n",
      "Row: 106\n",
      "Row: 250\n",
      "Row: 189\n",
      "Row: 245\n",
      "Row: 244\n",
      "Row: 208\n",
      "Row: 247\n",
      "Row: 234\n",
      "Row: 421\n",
      "Row: 232\n",
      "Row: 209\n",
      "Row: 233\n",
      "Row: 212\n",
      "Row: 89\n",
      "Row: 113\n",
      "Row: 111\n",
      "Row: 32\n",
      "Row: 44\n",
      "Row: 257\n",
      "Row: 362\n",
      "Row: 231\n",
      "Row: 204\n",
      "Row: 81\n",
      "Row: 360\n",
      "Row: 225\n",
      "Row: 272\n",
      "Row: 46\n",
      "Row: 107\n",
      "Row: 76\n",
      "Row: 202\n",
      "Row: 301\n",
      "Row: 90\n",
      "Row: 359\n",
      "Row: 294\n",
      "Row: 215\n",
      "Row: 355\n",
      "Row: 223\n",
      "Row: 78\n",
      "Row: 353\n",
      "Row: 252\n",
      "Row: 246\n",
      "Row: 183\n",
      "Row: 95\n",
      "Row: 248\n",
      "Row: 93\n",
      "Row: 197\n",
      "Row: 192\n",
      "Row: 109\n",
      "Row: 98\n",
      "Row: 249\n",
      "Row: 261\n",
      "Row: 42\n",
      "Row: 91\n",
      "Row: 429\n",
      "Row: 84\n",
      "Row: 73\n",
      "Row: 201\n",
      "Row: 297\n",
      "Row: 308\n",
      "Row: 235\n",
      "Row: 299\n",
      "Row: 77\n",
      "Row: 104\n",
      "Row: 74\n",
      "Row: 298\n",
      "Row: 305\n",
      "Row: 184\n",
      "Row: 300\n",
      "Row: 99\n",
      "Row: 103\n",
      "Row: 101\n",
      "Row: 236\n",
      "Row: 198\n",
      "Row: 199\n",
      "Row: 200\n",
      "Row: 306\n",
      "Row: 309\n",
      "Row: 96\n",
      "Row: 83\n",
      "Row: 290\n",
      "Row: 97\n",
      "Row: 41\n",
      "Row: 65\n",
      "Row: 304\n",
      "Row: 191\n",
      "Row: 302\n",
      "Row: 289\n",
      "Row: 87\n",
      "Row: 205\n",
      "Row: 311\n",
      "Row: 273\n",
      "Row: 296\n",
      "Row: 256\n",
      "Row: 269\n",
      "Row: 102\n",
      "Row: 195\n",
      "Row: 61\n",
      "Row: 313\n",
      "Row: 75\n",
      "Row: 14\n",
      "Row: 64\n",
      "Row: 287\n",
      "Row: 190\n",
      "Row: 312\n",
      "Row: 268\n",
      "Row: 288\n",
      "Row: 185\n",
      "Row: 307\n",
      "Row: 92\n",
      "Row: 271\n",
      "Row: 315\n",
      "Row: 178\n",
      "Row: 314\n",
      "Row: 80\n",
      "Row: 82\n",
      "Row: 85\n",
      "Row: 45\n",
      "Row: 270\n",
      "Row: 430\n",
      "Row: 70\n",
      "Row: 63\n",
      "Row: 194\n",
      "Row: 69\n",
      "Row: 79\n",
      "Row: 72\n",
      "Row: 60\n",
      "Row: 66\n",
      "Row: 293\n",
      "Row: 68\n",
      "Row: 303\n",
      "Row: 40\n",
      "Row: 59\n",
      "Row: 177\n",
      "Row: 356\n",
      "Row: 179\n",
      "Row: 363\n",
      "Row: 67\n",
      "Row: 181\n",
      "Row: 358\n",
      "Row: 15\n",
      "Row: 48\n",
      "Row: 193\n",
      "Row: 347\n",
      "Row: 370\n",
      "Row: 16\n",
      "Row: 55\n",
      "Row: 167\n",
      "Row: 58\n",
      "Row: 29\n",
      "Row: 265\n",
      "Row: 62\n",
      "Row: 56\n",
      "Row: 57\n",
      "Row: 6\n",
      "Row: 180\n",
      "Row: 282\n",
      "Row: 166\n",
      "Row: 51\n",
      "Row: 53\n",
      "Row: 182\n",
      "Row: 50\n",
      "Row: 170\n",
      "Row: 326\n",
      "Row: 39\n",
      "Row: 117\n",
      "Row: 47\n",
      "Row: 169\n",
      "Row: 168\n",
      "Row: 54\n",
      "Row: 52\n",
      "Row: 295\n",
      "Row: 171\n",
      "Row: 165\n",
      "Row: 286\n",
      "Row: 435\n",
      "Row: 291\n",
      "Row: 357\n",
      "Row: 323\n",
      "Row: 176\n",
      "Row: 361\n",
      "Row: 292\n",
      "Row: 162\n",
      "Row: 12\n",
      "Row: 26\n",
      "Row: 33\n",
      "Row: 13\n",
      "Row: 23\n",
      "Row: 364\n",
      "Row: 37\n",
      "Row: 21\n",
      "Row: 283\n",
      "Row: 340\n",
      "Row: 284\n",
      "Row: 36\n",
      "Row: 30\n",
      "Row: 31\n",
      "Row: 34\n",
      "Row: 196\n",
      "Row: 285\n",
      "Row: 38\n",
      "Row: 25\n",
      "Row: 325\n",
      "Row: 27\n",
      "Row: 350\n",
      "Row: 8\n",
      "Row: 20\n",
      "Row: 19\n",
      "Row: 24\n",
      "Row: 9\n",
      "Row: 17\n",
      "Row: 2\n",
      "Row: 7\n",
      "Row: 158\n",
      "Row: 342\n",
      "Row: 386\n",
      "Row: 4\n",
      "Row: 156\n",
      "Row: 372\n",
      "Row: 147\n",
      "Row: 348\n",
      "Row: 374\n",
      "Row: 10\n",
      "Row: 346\n",
      "Row: 139\n",
      "Row: 11\n",
      "Row: 371\n",
      "Row: 157\n",
      "Row: 3\n",
      "Row: 161\n",
      "Row: 5\n",
      "Row: 1\n",
      "Row: 140\n",
      "Row: 159\n",
      "Row: 351\n",
      "Row: 377\n",
      "Row: 341\n",
      "Row: 426\n",
      "Row: 378\n",
      "Row: 149\n",
      "Row: 349\n",
      "Row: 144\n",
      "Row: 409\n",
      "Row: 402\n",
      "Row: 387\n",
      "Row: 373\n",
      "Row: 400\n",
      "Row: 148\n",
      "Row: 335\n",
      "Row: 443\n",
      "Row: 384\n",
      "Row: 142\n",
      "Row: 153\n",
      "Row: 368\n",
      "Row: 336\n",
      "Row: 143\n",
      "Row: 152\n",
      "Row: 337\n",
      "Row: 391\n",
      "Row: 411\n",
      "Row: 327\n",
      "Row: 332\n",
      "Row: 328\n",
      "Row: 404\n",
      "Row: 385\n",
      "Row: 324\n",
      "Row: 344\n",
      "Row: 155\n",
      "Row: 365\n",
      "Row: 331\n",
      "Row: 366\n",
      "Row: 352\n",
      "Row: 375\n",
      "Row: 334\n",
      "Row: 333\n",
      "Row: 329\n",
      "Row: 389\n",
      "Row: 390\n",
      "Row: 369\n",
      "Row: 154\n",
      "Row: 403\n",
      "Row: 367\n",
      "Row: 145\n",
      "Row: 393\n",
      "Row: 434\n",
      "Row: 413\n",
      "Row: 412\n",
      "Row: 394\n",
      "Row: 150\n",
      "Row: 345\n",
      "Row: 415\n",
      "Row: 418\n",
      "Row: 380\n",
      "Row: 388\n",
      "Row: 399\n",
      "Row: 408\n",
      "Row: 160\n",
      "Row: 395\n",
      "Row: 376\n",
      "Row: 330\n",
      "Row: 416\n",
      "Row: 442\n",
      "Row: 397\n",
      "Row: 436\n",
      "Row: 439\n",
      "Row: 405\n",
      "Row: 343\n",
      "Row: 146\n",
      "Row: 428\n",
      "Row: 151\n",
      "Row: 427\n",
      "Row: 445\n",
      "Row: 419\n",
      "Row: 441\n",
      "Row: 392\n",
      "Row: 444\n",
      "Row: 440\n",
      "Row: 379\n",
      "Row: 141\n",
      "Row: 398\n",
      "Row: 425\n",
      "Row: 401\n",
      "Row: 447\n",
      "Row: 446\n",
      "Row: 396\n",
      "Row: 448\n",
      "Row: 449\n"
     ]
    }
   ],
   "source": [
    "total_dist_df = [] #this is where we will store all our distance matrices\n",
    "\n",
    "#print(f'Processing from: {dfx.year_signed.max()} to {dfx.year_signed.min()}')\n",
    "labels = list(text_df.index.values) #labels for dataframe\n",
    "labels = ['id'] + labels #append 'id'\n",
    "distances = []\n",
    "for x in text_df.iterrows():\n",
    "    print(f'Row: {x[0]}')\n",
    "    dist_tmp = [] #temporal list for current row\n",
    "    t1 = [words for sublist in x[1][5] for words in sublist]\n",
    "    dist_tmp.append(x[0]) #append index\n",
    "    for y in text_df.iterrows():\n",
    "        t2 = [words for sublist in y[1][5] for words in sublist]\n",
    "        d = model.wmdistance(t1, t2)\n",
    "        dist_tmp.append(d)\n",
    "    distances.append(dist_tmp) #once done with row, append to total distances\n",
    "total_dist_df = pd.DataFrame.from_records(distances, columns=labels, index=['id']) #once all distances for current df are coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save resulting dataframe to csv file\n",
    "#out_dir = \"saved_csv/glove-wiki-gigaword-300/total_ollie_stopwords/\"\n",
    "\n",
    "#csv_out = \"total_dist_df.csv\"\n",
    "#total_dist_df.to_csv(out_dir + csv_out, index = True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
